# SaaS Hunter

**Automated SaaS opportunity discovery from Reddit, GitHub, and Hacker News.**

ğŸ¯ **Mission:** Surface actionable pain points and unmet needs by monitoring public discussions across three high-signal sources.

---

## ğŸ“Š Quick Stats

- **Sources:** 14 subreddits, 11 GitHub repos, Ask HN
- **Cost:** $0/month (within free tiers)
- **Collection:** Autonomous via OpenClaw cron
- **Status:** âœ… Production (monitoring active since 2026-02-14)

---

## ğŸ—ï¸ Architecture

```
saas-hunter/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ config.py                    # Centralized configuration
â”‚   â”œâ”€â”€ utils.py                     # Shared utilities
â”‚   â”œâ”€â”€ reddit_monitor.py            # Reddit RSS collector
â”‚   â”œâ”€â”€ github_monitor.py            # GitHub API collector
â”‚   â”œâ”€â”€ hackernews_monitor.py        # HN Algolia collector
â”‚   â”œâ”€â”€ process_opportunities.py     # Scoring + dedup pipeline
â”‚   â”œâ”€â”€ generate_digest.py           # Daily digest generator
â”‚   â””â”€â”€ send_telegram_openclaw.py    # Telegram delivery queue
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # Timestamped collector outputs
â”‚   â”œâ”€â”€ processed/                   # Scored opportunities (JSONL)
â”‚   â”œâ”€â”€ digests/                     # Daily markdown summaries
â”‚   â”œâ”€â”€ telegram_outbox/             # Queued digests for delivery
â”‚   â””â”€â”€ seen_ids.json                # Deduplication tracking
â”œâ”€â”€ logs/                            # Execution logs
â”œâ”€â”€ scoring_config.json              # Scoring weights (v1.4-balanced)
â”œâ”€â”€ venv/                            # Python environment
â””â”€â”€ .env                             # API keys and settings
```

---

## ğŸš€ Setup

### 1. Install Dependencies

```bash
cd ~/saas-hunter
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

Requirements:
- feedparser
- requests
- beautifulsoup4
- python-dotenv

### 2. Configure Environment

Copy `.env.example` to `.env` and configure:

```bash
# GitHub token (required)
GITHUB_TOKEN=ghp_your_token_here

# OpenRouter API for LLM scoring (optional)
OPENROUTER_API_KEY=sk-or-v1-your_key_here

# Collection windows
GITHUB_HOURS_BACK=168  # 1 week
COLLECTION_HOURS_BACK=6  # Reddit/HN
```

Get GitHub token: https://github.com/settings/tokens (needs `public_repo` scope)

### 3. Test Collectors

```bash
cd scripts

# Reddit (RSS, no auth required)
../venv/bin/python3 reddit_monitor.py

# GitHub (requires token)
../venv/bin/python3 github_monitor.py

# HackerNews (free API)
../venv/bin/python3 hackernews_monitor.py

# Processing pipeline
../venv/bin/python3 process_opportunities.py

# Digest generation
../venv/bin/python3 generate_digest.py
```

---

## ğŸ¤– Autonomous Operation (OpenClaw)

The system runs autonomously via OpenClaw cron jobs:

### Cron Schedule

```
Reddit Monitor:       Every 3 hours
HackerNews Monitor:   Every 4 hours
GitHub Monitor:       Daily at 06:00 UTC
Process Pipeline:     Every 6 hours
Daily Digest:         Daily at 08:00 UTC
```

### Delivery Flow

1. Collectors gather opportunities â†’ `data/raw/`
2. Processor scores & deduplicates â†’ `data/processed/`
3. Digest generator creates markdown â†’ `data/digests/`
4. Telegram queue created â†’ `data/telegram_outbox/`
5. OpenClaw heartbeat delivers via Telegram

**No manual intervention required** â€” system is fully autonomous.

---

## ğŸ“Š Data Pipeline

### 1. Collection Layer

**Reddit (14 subreddits):**
- SaaS, Entrepreneur, startups, smallbusiness, productivity
- webdev, sysadmin, marketing, ecommerce, freelance
- sales, nocode, lowcode, saasmarketing
- **Filter:** 24 pain-point keywords
- **Volume:** 5-15 opps per run

**GitHub (11 repositories):**
- supabase, posthog, n8n, plausible, langchain
- excalidraw, trpc, formbricks, documenso, nocodb, directus
- **Filter:** Issues with reactions â‰¥2, last 7 days
- **Volume:** 0-5 opps per week

**HackerNews:**
- **Filter:** "Ask HN" posts with keywords or 5+ comments
- **Volume:** 0-3 opps per run

### 2. Processing Layer

**Features:**
- Data validation (schema checks)
- Scoring engine (config-driven, 0-100 points)
- Fuzzy deduplication (75% similarity threshold)
- LLM enhancement (Claude Haiku, opps â‰¥45 score)
- Domain classification

**Scoring Components:**
- Source credibility (0-20 pts)
- Engagement signals (0-25 pts)
- Pain point clarity (0-20 pts)
- Specificity (0-15 pts)
- Freshness (0-10 pts)
- Niche fit (0-10 pts)

### 3. Delivery Layer

**Daily Digest Format:**
- Top 3 opportunities (formatted for Telegram)
- Score-based ranking
- Source links
- Summary stats

**Delivery Method:**
- Queued in `telegram_outbox/`
- Picked up by OpenClaw heartbeat
- Sent via message tool to Telegram

---

## ğŸ“ Output Formats

### Raw Collection (JSON)
```json
{
  "scan_time": "2026-02-14T21:54:54Z",
  "total_opportunities": 5,
  "sources_scanned": ["SaaS", "Entrepreneur"],
  "opportunities": [
    {
      "source_id": "1r3tube",
      "source": "reddit:SaaS",
      "title": "Recommendations for distribution...",
      "body": "Hey guys. I'm exhausted...",
      "url": "https://reddit.com/r/SaaS/...",
      "published_utc": "2026-02-14T12:00:00",
      "engagement_data": {"keywords": ["tired of"]}
    }
  ]
}
```

### Processed Opportunities (JSONL)
```json
{
  "opportunity_id": "20260214205314-reddit-SaaS-...",
  "source": "reddit:SaaS",
  "title": "...",
  "body": "...",
  "score": 60,
  "domain": "marketing",
  "llm_enhanced": false,
  "processed_at": "2026-02-14T20:53:14Z"
}
```

### Daily Digest (Markdown)
```markdown
# SaaS Opportunities â€” February 14, 2026

## â­ High Potential (Score 60-79)

### 1. Title (Score: 60)
**Source:** reddit:SaaS | **Domain:** marketing
**Link:** https://...

## ğŸ’¡ Worth Exploring (Score 40-59)
...
```

---

## ğŸ”§ Configuration

### Scoring Config (`scoring_config.json`)

**Current:** v1.4-balanced

Key settings:
- Source weights: GitHub=20, Reddit=8-14, HN=15
- Pain signals: 14 points for strong frustration
- Willingness to pay: 16 points
- LLM threshold: 45 (triggers Claude Haiku enhancement)

### Scoring Profiles Available

- `scoring_config.json` â€” Balanced (current)
- `scoring_config_aggressive.json` â€” Higher scores
- `scoring_config_business.json` â€” B2B focused
- `scoring_config_pain_boost.json` â€” Pain point emphasis

Switch by updating `scripts/config.py` â†’ `SCORING_CONFIG_PATH`

---

## ğŸ“ˆ Performance (Feb 14, 2026)

### Collection Volume
- Reddit: 40-60 opps/day
- HN: 0-18 opps/day
- GitHub: 0-5 opps/week
- **Total: ~50-70 opps/day**

### Quality Distribution
- High (60+): 1-2% of opportunities
- Medium (40-59): 15-20%
- Low (<40): 78-85%

### System Health
- Collection success rate: >95%
- Validation pass rate: 100%
- Deduplication: ~5% duplicates removed
- LLM triggers: 0 (threshold=45, avg score=35)

---

## ğŸ’° Cost Breakdown

| Component | Service | Cost |
|-----------|---------|------|
| Collection | Reddit RSS, HN API, GitHub API | **$0** |
| Processing | Local Python | **$0** |
| LLM Scoring | OpenRouter (Claude Haiku) | **$0*** |
| Storage | Local files (~15MB) | **$0** |
| **TOTAL** | | **$0/month** |

*LLM not yet triggered (no opportunities reach threshold)

**Budget:** $15/month  
**Used:** $0  
**Available:** 100%

---

## ğŸ” Monitoring

Active monitoring since 2026-02-14 22:01 UTC.

**Tracked Metrics:**
- Job success rates
- Collection volume
- Score distribution
- LLM enhancement triggers
- Processing errors

**Review Cycle:** 24 hours

---

## ğŸ“– Documentation

### Core Docs
- **README.md** â€” This file (setup + overview)
- **ARCHITECTURE.md** â€” Detailed system design
- **SYSTEM_STATUS.md** â€” Current operational status

### Analysis Docs
- **PRODUCTION_TEST_RESULTS.md** â€” System testing results
- **BACKTEST_COMPARISON.md** â€” Scoring config comparison
- **KEYWORD_INSIGHTS.md** â€” Source analysis

### Implementation Docs
- **PHASE1_COMPLETE.md** â€” Collection layer implementation
- **PHASE2_LLM.md** â€” LLM scoring integration
- **DEPLOY.md** â€” Deployment guide

---

## ğŸ› Known Issues & Limitations

### Current
- **Low scoring:** 79% of opps score <40 (config tuning needed)
- **LLM never triggered:** Threshold=45, but avg score=35
- **Log rotation needed:** Logs growing (minor)

### Resolved
- âœ… GitHub 6h window too narrow â†’ Weekly
- âœ… Rate limit warnings â†’ Threshold adjusted
- âœ… Daily GitHub collection â†’ Changed to weekly
- âœ… Cron automation â†’ All jobs enabled

---

## ğŸš§ Roadmap

### Short-term (Week 1-2)
- [ ] Tune scoring config (test aggressive profile)
- [ ] Lower LLM threshold to 40
- [ ] Add log rotation
- [ ] Weekly summary reports

### Medium-term (Month 1-2)
- [ ] Semantic deduplication (embeddings)
- [ ] Trend detection across time
- [ ] Product Hunt integration
- [ ] Competitor tracking

### Long-term (Month 3+)
- [ ] ML-based scoring
- [ ] Outcome tracking (which opps became products?)
- [ ] Multi-user support
- [ ] Web dashboard

---

## ğŸ¤ Contributing

To customize for your niche:

1. **Add sources:** Edit `scripts/config.py`
   - `REDDIT_SUBREDDITS` â€” Add relevant subreddits
   - `GITHUB_REPOSITORIES` â€” Add relevant repos
   - `REDDIT_PAIN_KEYWORDS` â€” Add niche keywords

2. **Tune scoring:** Edit `scoring_config.json`
   - Adjust source weights
   - Add pain point phrases
   - Modify thresholds

3. **Adjust collection:** Edit `.env`
   - `COLLECTION_HOURS_BACK` â€” Reddit/HN lookback
   - `GITHUB_HOURS_BACK` â€” GitHub lookback

---

## ğŸ“„ License

MIT License - See LICENSE file

---

## ğŸ™ Credits

**Built with:**
- OpenClaw (autonomous agent framework)
- Python (collection + processing)
- Claude (LLM scoring)

**Data Sources:**
- Reddit (RSS feeds)
- GitHub (Search API)
- Hacker News (Algolia API)

---

**Status:** ğŸŸ¢ Production | **Monitoring:** Active | **Cost:** $0/month

Built with OpenClaw ğŸ¦
